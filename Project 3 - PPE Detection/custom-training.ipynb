{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1704189802794,"user":{"displayName":"Agiftsany Azhar","userId":"08070925752139831664"},"user_tz":-420},"id":"dr3rcxGXU6Tm","outputId":"2342e4e1-ad32-4ef2-f783-86b492bca798"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri May  3 15:22:03 2024       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 552.22                 Driver Version: 552.22         CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA GeForce RTX 4050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n","| N/A   46C    P8              2W /   85W |    1166MiB /   6141MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|    0   N/A  N/A     10208      C   ...rograms\\Python\\Python310\\python.exe      N/A      |\n","|    0   N/A  N/A     21736      C   ...rograms\\Python\\Python310\\python.exe      N/A      |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Package            Version\n","------------------ --------------------\n","asttokens          2.4.1\n","certifi            2024.2.2\n","charset-normalizer 3.3.2\n","colorama           0.4.6\n","comm               0.2.2\n","contourpy          1.2.1\n","cvzone             1.6.1\n","cycler             0.12.1\n","debugpy            1.8.1\n","decorator          5.1.1\n","exceptiongroup     1.2.1\n","executing          2.0.1\n","filelock           3.14.0\n","filterpy           1.4.5\n","fonttools          4.51.0\n","fsspec             2024.3.1\n","idna               3.7\n","imageio            2.34.1\n","intel-openmp       2021.4.0\n","ipykernel          6.29.4\n","ipython            8.24.0\n","jedi               0.19.1\n","Jinja2             3.1.3\n","jupyter_client     8.6.1\n","jupyter_core       5.7.2\n","kiwisolver         1.4.5\n","lazy_loader        0.4\n","MarkupSafe         2.1.5\n","matplotlib         3.8.4\n","matplotlib-inline  0.1.7\n","mkl                2021.4.0\n","mpmath             1.3.0\n","nest-asyncio       1.6.0\n","networkx           3.3\n","numpy              1.26.4\n","opencv-python      4.9.0.80\n","packaging          24.0\n","pandas             2.2.2\n","parso              0.8.4\n","pillow             10.3.0\n","pip                24.0\n","platformdirs       4.2.1\n","prompt-toolkit     3.0.43\n","psutil             5.9.8\n","pure-eval          0.2.2\n","py-cpuinfo         9.0.0\n","Pygments           2.17.2\n","pyparsing          3.1.2\n","python-dateutil    2.9.0.post0\n","pytz               2024.1\n","pywin32            306\n","PyYAML             6.0.1\n","pyzmq              26.0.3\n","requests           2.31.0\n","scikit-image       0.23.2\n","scipy              1.13.0\n","seaborn            0.13.2\n","setuptools         65.5.0\n","six                1.16.0\n","stack-data         0.6.3\n","sympy              1.12\n","tbb                2021.12.0\n","thop               0.1.1.post2209072238\n","tifffile           2024.4.24\n","torch              2.3.0+cu118\n","torchaudio         2.3.0+cu118\n","torchvision        0.18.0+cu118\n","tornado            6.4\n","tqdm               4.66.4\n","traitlets          5.14.3\n","typing_extensions  4.11.0\n","tzdata             2024.1\n","ultralytics        8.2.7\n","urllib3            2.2.1\n","wcwidth            0.2.13\n"]}],"source":["!pip list"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"AZnJEewRa9DM"},"outputs":[],"source":["from ultralytics import YOLO"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14714,"status":"ok","timestamp":1704189871511,"user":{"displayName":"Agiftsany Azhar","userId":"08070925752139831664"},"user_tz":-420},"id":"UaYvKs_QbEso","outputId":"ce3a9049-9830-4cd1-ac43-eaf006bd95b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.7 üöÄ Python-3.10.11 torch-2.3.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n","YOLOv8l summary (fused): 268 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs\n","\n","Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n","image 1/1 f:\\Tutorial\\learn-yolo-object-detection\\Project 3 - PPE Detection\\bus.jpg: 640x480 5 persons, 1 bicycle, 1 bus, 133.3ms\n","Speed: 2.1ms preprocess, 133.3ms inference, 840.7ms postprocess per image at shape (1, 3, 640, 480)\n","Results saved to \u001b[1mf:\\Tutorial\\learn-yolo-object-detection\\runs\\detect\\predict4\u001b[0m\n","üí° Learn more at https://docs.ultralytics.com/modes/predict\n"]}],"source":["!yolo task=detect mode=predict model=yolov8l.pt conf=0.25 source=\"https://ultralytics.com/images/bus.jpg\""]},{"cell_type":"markdown","metadata":{"id":"6Bchw_Pob8md"},"source":["# Custom Data Training"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":823842,"status":"ok","timestamp":1704190705064,"user":{"displayName":"Agiftsany Azhar","userId":"08070925752139831664"},"user_tz":-420},"id":"Od_WByNscD3I","outputId":"ff82d479-0d7a-4d3a-a0a4-3d980442e768"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING ‚ö†Ô∏è 'data' argument is missing. Using default 'data=coco8.yaml'.\n","Ultralytics YOLOv8.2.7 üöÄ Python-3.10.11 torch-2.3.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n","\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8l.pt, data=coco8.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=0.25, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=Construction Site Safety/data.yaml, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=f:\\Tutorial\\learn-yolo-object-detection\\runs\\detect\\train5\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n","  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n","  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n","  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n","  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n","  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n"," 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n"," 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n"," 22        [15, 18, 21]  1   5644480  ultralytics.nn.modules.head.Detect           [80, [256, 512, 512]]         \n","Model summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n","\n","Transferred 595/595 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","Plotting labels to f:\\Tutorial\\learn-yolo-object-detection\\runs\\detect\\train5\\labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mf:\\Tutorial\\learn-yolo-object-detection\\runs\\detect\\train5\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["f:\\Tutorial\\learn-yolo-object-detection\\.venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n","\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning F:\\Tutorial\\datasets\\coco8\\labels\\train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning F:\\Tutorial\\datasets\\coco8\\labels\\train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n","\n","\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\Tutorial\\datasets\\coco8\\labels\\val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\Tutorial\\datasets\\coco8\\labels\\val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n","\n","  0%|          | 0/1 [00:00<?, ?it/s]\n","  0%|          | 0/1 [00:00<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"C:\\Users\\agift\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"C:\\Users\\agift\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"f:\\Tutorial\\learn-yolo-object-detection\\.venv\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n","    sys.exit(entrypoint())\n","  File \"f:\\Tutorial\\learn-yolo-object-detection\\.venv\\lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 582, in entrypoint\n","    getattr(model, mode)(**overrides)  # default args from model\n","  File \"f:\\Tutorial\\learn-yolo-object-detection\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 673, in train\n","    self.trainer.train()\n","  File \"f:\\Tutorial\\learn-yolo-object-detection\\.venv\\lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 199, in train\n","    self._do_train(world_size)\n","  File \"f:\\Tutorial\\learn-yolo-object-detection\\.venv\\lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 353, in _do_train\n","    for i, batch in pbar:\n","  File \"f:\\Tutorial\\learn-yolo-object-detection\\.venv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n","    for obj in iterable:\n","  File \"f:\\Tutorial\\learn-yolo-object-detection\\.venv\\lib\\site-packages\\ultralytics\\data\\build.py\", line 50, in __iter__\n","    yield next(self.iterator)\n","  File \"f:\\Tutorial\\learn-yolo-object-detection\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 631, in __next__\n","    data = self._next_data()\n","  File \"f:\\Tutorial\\learn-yolo-object-detection\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1346, in _next_data\n","    return self._process_data(data)\n","  File \"f:\\Tutorial\\learn-yolo-object-detection\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1372, in _process_data\n","    data.reraise()\n","  File \"f:\\Tutorial\\learn-yolo-object-detection\\.venv\\lib\\site-packages\\torch\\_utils.py\", line 705, in reraise\n","    raise exception\n","AttributeError: Caught AttributeError in DataLoader worker process 0.\n","Original Traceback (most recent call last):\n","  File \"f:\\Tutorial\\learn-yolo-object-detection\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 250, in _worker_loop\n","    init_fn(worker_id)\n","  File \"f:\\Tutorial\\learn-yolo-object-detection\\.venv\\lib\\site-packages\\ultralytics\\data\\build.py\", line 84, in seed_worker\n","    os.sched_setaffinity(0, range(NUM_THREADS))  # fix https://github.com/ultralytics/ultralytics/pull/11195\n","AttributeError: module 'os' has no attribute 'sched_setaffinity'\n","\n"]}],"source":["!yolo task=detect mode=train model=yolov8l.pt conf=0.25 source=\"Construction Site Safety/data.yaml\" epochs=50 imgsz=640"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMFyv86nInJaS5PqGYVzukd","gpuType":"T4","mount_file_id":"14wnMSxmtfS2wD0Cat6ReRAnqkHesfJ2c","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
